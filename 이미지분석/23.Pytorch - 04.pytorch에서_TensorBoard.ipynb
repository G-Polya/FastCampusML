{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "\n",
    "lr = 0.001\n",
    "momentum = 0.5\n",
    "\n",
    "batch_size = 64\n",
    "test_batch_size = 64\n",
    "\n",
    "epochs = 1000\n",
    "no_cuda = False\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train_paths = glob('dataset/mnist_png/training/*/*.png')[:1000]\n",
    "test_paths = glob('dataset/mnist_png/testing/*/*.png')[:1000]\n",
    "\n",
    "len(train_paths), len(test_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, data_paths, transform=None):\n",
    "\n",
    "        self.data_paths = data_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.data_paths[idx]\n",
    "        image = Image.open(path).convert(\"L\")\n",
    "        label = int(path.split('\\\\')[-2])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    Dataset(train_paths, \n",
    "            transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(), \n",
    "                transforms.ToTensor(), \n",
    "                transforms.Normalize(\n",
    "                    mean=[0.406], \n",
    "                    std=[0.225])])\n",
    "           ),\n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    Dataset(test_paths,\n",
    "           transforms.Compose([\n",
    "               transforms.ToTensor(), \n",
    "               transforms.Normalize(\n",
    "                   mean=[0.406], \n",
    "                   std=[0.225])])\n",
    "           ),\n",
    "    batch_size=batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1000 (0%)]\tLoss: 0.002523\n",
      "\n",
      "Test set: Average loss: 0.1292, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 19 [0/1000 (0%)]\tLoss: 0.002474\n",
      "\n",
      "Test set: Average loss: 0.1301, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 20 [0/1000 (0%)]\tLoss: 0.002206\n",
      "\n",
      "Test set: Average loss: 0.1310, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 21 [0/1000 (0%)]\tLoss: 0.001963\n",
      "\n",
      "Test set: Average loss: 0.1319, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 22 [0/1000 (0%)]\tLoss: 0.002030\n",
      "\n",
      "Test set: Average loss: 0.1327, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 23 [0/1000 (0%)]\tLoss: 0.001894\n",
      "\n",
      "Test set: Average loss: 0.1335, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 24 [0/1000 (0%)]\tLoss: 0.001759\n",
      "\n",
      "Test set: Average loss: 0.1343, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 25 [0/1000 (0%)]\tLoss: 0.001713\n",
      "\n",
      "Test set: Average loss: 0.1350, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 26 [0/1000 (0%)]\tLoss: 0.001560\n",
      "\n",
      "Test set: Average loss: 0.1358, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 27 [0/1000 (0%)]\tLoss: 0.001554\n",
      "\n",
      "Test set: Average loss: 0.1365, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 28 [0/1000 (0%)]\tLoss: 0.001487\n",
      "\n",
      "Test set: Average loss: 0.1371, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 29 [0/1000 (0%)]\tLoss: 0.001304\n",
      "\n",
      "Test set: Average loss: 0.1378, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 30 [0/1000 (0%)]\tLoss: 0.001359\n",
      "\n",
      "Test set: Average loss: 0.1384, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 31 [0/1000 (0%)]\tLoss: 0.001176\n",
      "\n",
      "Test set: Average loss: 0.1390, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 32 [0/1000 (0%)]\tLoss: 0.001170\n",
      "\n",
      "Test set: Average loss: 0.1396, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 33 [0/1000 (0%)]\tLoss: 0.001152\n",
      "\n",
      "Test set: Average loss: 0.1402, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 34 [0/1000 (0%)]\tLoss: 0.001084\n",
      "\n",
      "Test set: Average loss: 0.1408, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 35 [0/1000 (0%)]\tLoss: 0.000984\n",
      "\n",
      "Test set: Average loss: 0.1413, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 36 [0/1000 (0%)]\tLoss: 0.001110\n",
      "\n",
      "Test set: Average loss: 0.1419, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 37 [0/1000 (0%)]\tLoss: 0.000959\n",
      "\n",
      "Test set: Average loss: 0.1424, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 38 [0/1000 (0%)]\tLoss: 0.001046\n",
      "\n",
      "Test set: Average loss: 0.1429, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 39 [0/1000 (0%)]\tLoss: 0.000937\n",
      "\n",
      "Test set: Average loss: 0.1434, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 40 [0/1000 (0%)]\tLoss: 0.000875\n",
      "\n",
      "Test set: Average loss: 0.1439, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 41 [0/1000 (0%)]\tLoss: 0.000966\n",
      "\n",
      "Test set: Average loss: 0.1444, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 42 [0/1000 (0%)]\tLoss: 0.000781\n",
      "\n",
      "Test set: Average loss: 0.1448, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 43 [0/1000 (0%)]\tLoss: 0.000810\n",
      "\n",
      "Test set: Average loss: 0.1453, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 44 [0/1000 (0%)]\tLoss: 0.000901\n",
      "\n",
      "Test set: Average loss: 0.1457, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 45 [0/1000 (0%)]\tLoss: 0.000723\n",
      "\n",
      "Test set: Average loss: 0.1461, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 46 [0/1000 (0%)]\tLoss: 0.000884\n",
      "\n",
      "Test set: Average loss: 0.1466, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 47 [0/1000 (0%)]\tLoss: 0.000836\n",
      "\n",
      "Test set: Average loss: 0.1470, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 48 [0/1000 (0%)]\tLoss: 0.000821\n",
      "\n",
      "Test set: Average loss: 0.1474, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 49 [0/1000 (0%)]\tLoss: 0.000653\n",
      "\n",
      "Test set: Average loss: 0.1478, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 50 [0/1000 (0%)]\tLoss: 0.000669\n",
      "\n",
      "Test set: Average loss: 0.1482, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 51 [0/1000 (0%)]\tLoss: 0.000618\n",
      "\n",
      "Test set: Average loss: 0.1486, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 52 [0/1000 (0%)]\tLoss: 0.000676\n",
      "\n",
      "Test set: Average loss: 0.1489, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 53 [0/1000 (0%)]\tLoss: 0.000676\n",
      "\n",
      "Test set: Average loss: 0.1493, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 54 [0/1000 (0%)]\tLoss: 0.000551\n",
      "\n",
      "Test set: Average loss: 0.1497, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 55 [0/1000 (0%)]\tLoss: 0.000614\n",
      "\n",
      "Test set: Average loss: 0.1500, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 56 [0/1000 (0%)]\tLoss: 0.000617\n",
      "\n",
      "Test set: Average loss: 0.1504, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 57 [0/1000 (0%)]\tLoss: 0.000541\n",
      "\n",
      "Test set: Average loss: 0.1507, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 58 [0/1000 (0%)]\tLoss: 0.000619\n",
      "\n",
      "Test set: Average loss: 0.1511, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 59 [0/1000 (0%)]\tLoss: 0.000617\n",
      "\n",
      "Test set: Average loss: 0.1514, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 60 [0/1000 (0%)]\tLoss: 0.000499\n",
      "\n",
      "Test set: Average loss: 0.1517, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 61 [0/1000 (0%)]\tLoss: 0.000555\n",
      "\n",
      "Test set: Average loss: 0.1521, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 62 [0/1000 (0%)]\tLoss: 0.000567\n",
      "\n",
      "Test set: Average loss: 0.1524, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 63 [0/1000 (0%)]\tLoss: 0.000518\n",
      "\n",
      "Test set: Average loss: 0.1527, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 64 [0/1000 (0%)]\tLoss: 0.000515\n",
      "\n",
      "Test set: Average loss: 0.1530, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 65 [0/1000 (0%)]\tLoss: 0.000506\n",
      "\n",
      "Test set: Average loss: 0.1533, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 66 [0/1000 (0%)]\tLoss: 0.000466\n",
      "\n",
      "Test set: Average loss: 0.1536, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 67 [0/1000 (0%)]\tLoss: 0.000477\n",
      "\n",
      "Test set: Average loss: 0.1539, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 68 [0/1000 (0%)]\tLoss: 0.000509\n",
      "\n",
      "Test set: Average loss: 0.1542, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 69 [0/1000 (0%)]\tLoss: 0.000460\n",
      "\n",
      "Test set: Average loss: 0.1545, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 70 [0/1000 (0%)]\tLoss: 0.000412\n",
      "\n",
      "Test set: Average loss: 0.1548, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 71 [0/1000 (0%)]\tLoss: 0.000408\n",
      "\n",
      "Test set: Average loss: 0.1550, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 72 [0/1000 (0%)]\tLoss: 0.000481\n",
      "\n",
      "Test set: Average loss: 0.1553, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 73 [0/1000 (0%)]\tLoss: 0.000484\n",
      "\n",
      "Test set: Average loss: 0.1556, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 74 [0/1000 (0%)]\tLoss: 0.000460\n",
      "\n",
      "Test set: Average loss: 0.1558, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 75 [0/1000 (0%)]\tLoss: 0.000397\n",
      "\n",
      "Test set: Average loss: 0.1561, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 76 [0/1000 (0%)]\tLoss: 0.000411\n",
      "\n",
      "Test set: Average loss: 0.1564, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 77 [0/1000 (0%)]\tLoss: 0.000466\n",
      "\n",
      "Test set: Average loss: 0.1566, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 78 [0/1000 (0%)]\tLoss: 0.000406\n",
      "\n",
      "Test set: Average loss: 0.1569, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 79 [0/1000 (0%)]\tLoss: 0.000427\n",
      "\n",
      "Test set: Average loss: 0.1571, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 80 [0/1000 (0%)]\tLoss: 0.000448\n",
      "\n",
      "Test set: Average loss: 0.1574, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 81 [0/1000 (0%)]\tLoss: 0.000389\n",
      "\n",
      "Test set: Average loss: 0.1576, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 82 [0/1000 (0%)]\tLoss: 0.000364\n",
      "\n",
      "Test set: Average loss: 0.1579, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 83 [0/1000 (0%)]\tLoss: 0.000339\n",
      "\n",
      "Test set: Average loss: 0.1581, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 84 [0/1000 (0%)]\tLoss: 0.000405\n",
      "\n",
      "Test set: Average loss: 0.1583, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 85 [0/1000 (0%)]\tLoss: 0.000365\n",
      "\n",
      "Test set: Average loss: 0.1586, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 86 [0/1000 (0%)]\tLoss: 0.000336\n",
      "\n",
      "Test set: Average loss: 0.1588, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 87 [0/1000 (0%)]\tLoss: 0.000361\n",
      "\n",
      "Test set: Average loss: 0.1590, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 88 [0/1000 (0%)]\tLoss: 0.000337\n",
      "\n",
      "Test set: Average loss: 0.1593, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 89 [0/1000 (0%)]\tLoss: 0.000355\n",
      "\n",
      "Test set: Average loss: 0.1595, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 90 [0/1000 (0%)]\tLoss: 0.000352\n",
      "\n",
      "Test set: Average loss: 0.1597, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 91 [0/1000 (0%)]\tLoss: 0.000311\n",
      "\n",
      "Test set: Average loss: 0.1599, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 92 [0/1000 (0%)]\tLoss: 0.000314\n",
      "\n",
      "Test set: Average loss: 0.1601, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 93 [0/1000 (0%)]\tLoss: 0.000320\n",
      "\n",
      "Test set: Average loss: 0.1603, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 94 [0/1000 (0%)]\tLoss: 0.000319\n",
      "\n",
      "Test set: Average loss: 0.1606, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 95 [0/1000 (0%)]\tLoss: 0.000369\n",
      "\n",
      "Test set: Average loss: 0.1608, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 96 [0/1000 (0%)]\tLoss: 0.000322\n",
      "\n",
      "Test set: Average loss: 0.1610, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 97 [0/1000 (0%)]\tLoss: 0.000288\n",
      "\n",
      "Test set: Average loss: 0.1612, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 98 [0/1000 (0%)]\tLoss: 0.000301\n",
      "\n",
      "Test set: Average loss: 0.1614, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 99 [0/1000 (0%)]\tLoss: 0.000270\n",
      "\n",
      "Test set: Average loss: 0.1616, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 100 [0/1000 (0%)]\tLoss: 0.000266\n",
      "\n",
      "Test set: Average loss: 0.1618, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 101 [0/1000 (0%)]\tLoss: 0.000352\n",
      "\n",
      "Test set: Average loss: 0.1620, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 102 [0/1000 (0%)]\tLoss: 0.000337\n",
      "\n",
      "Test set: Average loss: 0.1622, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 103 [0/1000 (0%)]\tLoss: 0.000307\n",
      "\n",
      "Test set: Average loss: 0.1624, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 104 [0/1000 (0%)]\tLoss: 0.000287\n",
      "\n",
      "Test set: Average loss: 0.1626, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 105 [0/1000 (0%)]\tLoss: 0.000287\n",
      "\n",
      "Test set: Average loss: 0.1627, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 106 [0/1000 (0%)]\tLoss: 0.000261\n",
      "\n",
      "Test set: Average loss: 0.1629, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 107 [0/1000 (0%)]\tLoss: 0.000320\n",
      "\n",
      "Test set: Average loss: 0.1631, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 108 [0/1000 (0%)]\tLoss: 0.000260\n",
      "\n",
      "Test set: Average loss: 0.1633, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 109 [0/1000 (0%)]\tLoss: 0.000250\n",
      "\n",
      "Test set: Average loss: 0.1635, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 110 [0/1000 (0%)]\tLoss: 0.000249\n",
      "\n",
      "Test set: Average loss: 0.1637, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 111 [0/1000 (0%)]\tLoss: 0.000299\n",
      "\n",
      "Test set: Average loss: 0.1638, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 112 [0/1000 (0%)]\tLoss: 0.000283\n",
      "\n",
      "Test set: Average loss: 0.1640, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 113 [0/1000 (0%)]\tLoss: 0.000265\n",
      "\n",
      "Test set: Average loss: 0.1642, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 114 [0/1000 (0%)]\tLoss: 0.000265\n",
      "\n",
      "Test set: Average loss: 0.1644, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 115 [0/1000 (0%)]\tLoss: 0.000266\n",
      "\n",
      "Test set: Average loss: 0.1645, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 116 [0/1000 (0%)]\tLoss: 0.000272\n",
      "\n",
      "Test set: Average loss: 0.1647, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 117 [0/1000 (0%)]\tLoss: 0.000249\n",
      "\n",
      "Test set: Average loss: 0.1649, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 118 [0/1000 (0%)]\tLoss: 0.000226\n",
      "\n",
      "Test set: Average loss: 0.1651, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 119 [0/1000 (0%)]\tLoss: 0.000267\n",
      "\n",
      "Test set: Average loss: 0.1652, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 120 [0/1000 (0%)]\tLoss: 0.000245\n",
      "\n",
      "Test set: Average loss: 0.1654, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 121 [0/1000 (0%)]\tLoss: 0.000215\n",
      "\n",
      "Test set: Average loss: 0.1656, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 122 [0/1000 (0%)]\tLoss: 0.000230\n",
      "\n",
      "Test set: Average loss: 0.1657, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 123 [0/1000 (0%)]\tLoss: 0.000244\n",
      "\n",
      "Test set: Average loss: 0.1659, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 124 [0/1000 (0%)]\tLoss: 0.000213\n",
      "\n",
      "Test set: Average loss: 0.1660, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 125 [0/1000 (0%)]\tLoss: 0.000227\n",
      "\n",
      "Test set: Average loss: 0.1662, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 126 [0/1000 (0%)]\tLoss: 0.000215\n",
      "\n",
      "Test set: Average loss: 0.1664, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 127 [0/1000 (0%)]\tLoss: 0.000250\n",
      "\n",
      "Test set: Average loss: 0.1665, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 128 [0/1000 (0%)]\tLoss: 0.000183\n",
      "\n",
      "Test set: Average loss: 0.1667, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 129 [0/1000 (0%)]\tLoss: 0.000208\n",
      "\n",
      "Test set: Average loss: 0.1668, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 130 [0/1000 (0%)]\tLoss: 0.000220\n",
      "\n",
      "Test set: Average loss: 0.1670, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 131 [0/1000 (0%)]\tLoss: 0.000220\n",
      "\n",
      "Test set: Average loss: 0.1671, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 132 [0/1000 (0%)]\tLoss: 0.000227\n",
      "\n",
      "Test set: Average loss: 0.1673, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 133 [0/1000 (0%)]\tLoss: 0.000206\n",
      "\n",
      "Test set: Average loss: 0.1674, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 134 [0/1000 (0%)]\tLoss: 0.000214\n",
      "\n",
      "Test set: Average loss: 0.1676, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 135 [0/1000 (0%)]\tLoss: 0.000208\n",
      "\n",
      "Test set: Average loss: 0.1677, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 136 [0/1000 (0%)]\tLoss: 0.000228\n",
      "\n",
      "Test set: Average loss: 0.1679, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 137 [0/1000 (0%)]\tLoss: 0.000216\n",
      "\n",
      "Test set: Average loss: 0.1680, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 138 [0/1000 (0%)]\tLoss: 0.000198\n",
      "\n",
      "Test set: Average loss: 0.1682, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 139 [0/1000 (0%)]\tLoss: 0.000199\n",
      "\n",
      "Test set: Average loss: 0.1683, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 140 [0/1000 (0%)]\tLoss: 0.000195\n",
      "\n",
      "Test set: Average loss: 0.1685, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 141 [0/1000 (0%)]\tLoss: 0.000177\n",
      "\n",
      "Test set: Average loss: 0.1686, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 142 [0/1000 (0%)]\tLoss: 0.000229\n",
      "\n",
      "Test set: Average loss: 0.1687, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 143 [0/1000 (0%)]\tLoss: 0.000190\n",
      "\n",
      "Test set: Average loss: 0.1689, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 144 [0/1000 (0%)]\tLoss: 0.000225\n",
      "\n",
      "Test set: Average loss: 0.1690, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 145 [0/1000 (0%)]\tLoss: 0.000187\n",
      "\n",
      "Test set: Average loss: 0.1691, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 146 [0/1000 (0%)]\tLoss: 0.000180\n",
      "\n",
      "Test set: Average loss: 0.1693, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 147 [0/1000 (0%)]\tLoss: 0.000181\n",
      "\n",
      "Test set: Average loss: 0.1694, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 148 [0/1000 (0%)]\tLoss: 0.000191\n",
      "\n",
      "Test set: Average loss: 0.1696, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 149 [0/1000 (0%)]\tLoss: 0.000183\n",
      "\n",
      "Test set: Average loss: 0.1697, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 150 [0/1000 (0%)]\tLoss: 0.000181\n",
      "\n",
      "Test set: Average loss: 0.1698, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 151 [0/1000 (0%)]\tLoss: 0.000192\n",
      "\n",
      "Test set: Average loss: 0.1700, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 152 [0/1000 (0%)]\tLoss: 0.000154\n",
      "\n",
      "Test set: Average loss: 0.1701, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 153 [0/1000 (0%)]\tLoss: 0.000172\n",
      "\n",
      "Test set: Average loss: 0.1702, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 154 [0/1000 (0%)]\tLoss: 0.000171\n",
      "\n",
      "Test set: Average loss: 0.1703, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 155 [0/1000 (0%)]\tLoss: 0.000169\n",
      "\n",
      "Test set: Average loss: 0.1705, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 156 [0/1000 (0%)]\tLoss: 0.000156\n",
      "\n",
      "Test set: Average loss: 0.1706, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 157 [0/1000 (0%)]\tLoss: 0.000166\n",
      "\n",
      "Test set: Average loss: 0.1707, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 158 [0/1000 (0%)]\tLoss: 0.000146\n",
      "\n",
      "Test set: Average loss: 0.1709, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 159 [0/1000 (0%)]\tLoss: 0.000173\n",
      "\n",
      "Test set: Average loss: 0.1710, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 160 [0/1000 (0%)]\tLoss: 0.000181\n",
      "\n",
      "Test set: Average loss: 0.1711, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 161 [0/1000 (0%)]\tLoss: 0.000203\n",
      "\n",
      "Test set: Average loss: 0.1712, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 162 [0/1000 (0%)]\tLoss: 0.000145\n",
      "\n",
      "Test set: Average loss: 0.1713, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 163 [0/1000 (0%)]\tLoss: 0.000194\n",
      "\n",
      "Test set: Average loss: 0.1715, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 164 [0/1000 (0%)]\tLoss: 0.000139\n",
      "\n",
      "Test set: Average loss: 0.1716, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 165 [0/1000 (0%)]\tLoss: 0.000172\n",
      "\n",
      "Test set: Average loss: 0.1717, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 166 [0/1000 (0%)]\tLoss: 0.000181\n",
      "\n",
      "Test set: Average loss: 0.1718, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 167 [0/1000 (0%)]\tLoss: 0.000169\n",
      "\n",
      "Test set: Average loss: 0.1720, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 168 [0/1000 (0%)]\tLoss: 0.000187\n",
      "\n",
      "Test set: Average loss: 0.1721, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 169 [0/1000 (0%)]\tLoss: 0.000158\n",
      "\n",
      "Test set: Average loss: 0.1722, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 170 [0/1000 (0%)]\tLoss: 0.000147\n",
      "\n",
      "Test set: Average loss: 0.1723, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 171 [0/1000 (0%)]\tLoss: 0.000179\n",
      "\n",
      "Test set: Average loss: 0.1724, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 172 [0/1000 (0%)]\tLoss: 0.000157\n",
      "\n",
      "Test set: Average loss: 0.1725, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 173 [0/1000 (0%)]\tLoss: 0.000163\n",
      "\n",
      "Test set: Average loss: 0.1727, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 174 [0/1000 (0%)]\tLoss: 0.000152\n",
      "\n",
      "Test set: Average loss: 0.1728, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 175 [0/1000 (0%)]\tLoss: 0.000169\n",
      "\n",
      "Test set: Average loss: 0.1729, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 176 [0/1000 (0%)]\tLoss: 0.000148\n",
      "\n",
      "Test set: Average loss: 0.1730, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 177 [0/1000 (0%)]\tLoss: 0.000163\n",
      "\n",
      "Test set: Average loss: 0.1731, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 178 [0/1000 (0%)]\tLoss: 0.000150\n",
      "\n",
      "Test set: Average loss: 0.1732, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 179 [0/1000 (0%)]\tLoss: 0.000149\n",
      "\n",
      "Test set: Average loss: 0.1733, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 180 [0/1000 (0%)]\tLoss: 0.000161\n",
      "\n",
      "Test set: Average loss: 0.1734, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 181 [0/1000 (0%)]\tLoss: 0.000144\n",
      "\n",
      "Test set: Average loss: 0.1736, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 182 [0/1000 (0%)]\tLoss: 0.000132\n",
      "\n",
      "Test set: Average loss: 0.1737, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 183 [0/1000 (0%)]\tLoss: 0.000157\n",
      "\n",
      "Test set: Average loss: 0.1738, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 184 [0/1000 (0%)]\tLoss: 0.000146\n",
      "\n",
      "Test set: Average loss: 0.1739, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 185 [0/1000 (0%)]\tLoss: 0.000148\n",
      "\n",
      "Test set: Average loss: 0.1740, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 186 [0/1000 (0%)]\tLoss: 0.000135\n",
      "\n",
      "Test set: Average loss: 0.1741, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 187 [0/1000 (0%)]\tLoss: 0.000136\n",
      "\n",
      "Test set: Average loss: 0.1742, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 188 [0/1000 (0%)]\tLoss: 0.000165\n",
      "\n",
      "Test set: Average loss: 0.1743, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 189 [0/1000 (0%)]\tLoss: 0.000135\n",
      "\n",
      "Test set: Average loss: 0.1744, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 190 [0/1000 (0%)]\tLoss: 0.000136\n",
      "\n",
      "Test set: Average loss: 0.1745, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 191 [0/1000 (0%)]\tLoss: 0.000124\n",
      "\n",
      "Test set: Average loss: 0.1746, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 192 [0/1000 (0%)]\tLoss: 0.000165\n",
      "\n",
      "Test set: Average loss: 0.1747, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 193 [0/1000 (0%)]\tLoss: 0.000158\n",
      "\n",
      "Test set: Average loss: 0.1748, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 194 [0/1000 (0%)]\tLoss: 0.000154\n",
      "\n",
      "Test set: Average loss: 0.1749, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 195 [0/1000 (0%)]\tLoss: 0.000153\n",
      "\n",
      "Test set: Average loss: 0.1750, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 196 [0/1000 (0%)]\tLoss: 0.000138\n",
      "\n",
      "Test set: Average loss: 0.1751, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 197 [0/1000 (0%)]\tLoss: 0.000160\n",
      "\n",
      "Test set: Average loss: 0.1752, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 198 [0/1000 (0%)]\tLoss: 0.000123\n",
      "\n",
      "Test set: Average loss: 0.1753, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 199 [0/1000 (0%)]\tLoss: 0.000136\n",
      "\n",
      "Test set: Average loss: 0.1754, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 200 [0/1000 (0%)]\tLoss: 0.000144\n",
      "\n",
      "Test set: Average loss: 0.1755, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 201 [0/1000 (0%)]\tLoss: 0.000127\n",
      "\n",
      "Test set: Average loss: 0.1756, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 202 [0/1000 (0%)]\tLoss: 0.000112\n",
      "\n",
      "Test set: Average loss: 0.1757, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 203 [0/1000 (0%)]\tLoss: 0.000123\n",
      "\n",
      "Test set: Average loss: 0.1758, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 204 [0/1000 (0%)]\tLoss: 0.000128\n",
      "\n",
      "Test set: Average loss: 0.1759, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 205 [0/1000 (0%)]\tLoss: 0.000118\n",
      "\n",
      "Test set: Average loss: 0.1760, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 206 [0/1000 (0%)]\tLoss: 0.000111\n",
      "\n",
      "Test set: Average loss: 0.1761, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 207 [0/1000 (0%)]\tLoss: 0.000130\n",
      "\n",
      "Test set: Average loss: 0.1762, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 208 [0/1000 (0%)]\tLoss: 0.000118\n",
      "\n",
      "Test set: Average loss: 0.1763, Accuracy: 980/1000 (98%)\n",
      "\n",
      "Train Epoch: 209 [0/1000 (0%)]\tLoss: 0.000141\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c35b9ec8c53f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-3a39cbbb3770>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \"\"\"\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m         \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    # Train Mode\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)  # https://pytorch.org/docs/stable/nn.html#nll-loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    \n",
    "    # Test mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))\n",
    "\n",
    "    if epoch == 0:\n",
    "        grid = torchvision.utils.make_grid(data)\n",
    "        writer.add_image(\"images\", grid,epoch)\n",
    "        writer.add_graph(model, data)\n",
    "    writer.add_scalar(\"Loss/train/\", loss,epoch)\n",
    "    writer.add_scalar(\"Loss/test/\", test_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/test\", accuracy, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-3f214e47",
   "display_name": "Python 3.7.3 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}